{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b35e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5641a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_admission=pd.read_csv('ADMISSIONS.csv')\n",
    "df_patient=pd.read_csv('PATIENTS.csv')\n",
    "df_notes=pd.read_csv('NOTEEVENTS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9a8f97",
   "metadata": {},
   "source": [
    "# Part 1: Preprocess df_admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge df_admission and df_patient\n",
    "df_admission=df_admission.merge(df_patient.iloc[:,1:4], on='SUBJECT_ID', how='left')\n",
    "df_admission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to Datetime for the table\n",
    "df_admission.ADMITTIME = pd.to_datetime(df_admission.ADMITTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "df_admission.DISCHTIME = pd.to_datetime(df_admission.DISCHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "df_admission.DEATHTIME = pd.to_datetime(df_admission.DEATHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "df_admission.DOB=pd.to_datetime(df_admission.DOB, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_admission['AGE_UPON_ADMIT']=''\n",
    "for i in range(len(df_admission)):\n",
    "    df_admission['AGE_UPON_ADMIT'][i]=round((df_admission.ADMITTIME[i].to_pydatetime()-df_admission.DOB[i].to_pydatetime()).days/365,0)\n",
    "df_admission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38193310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep patients between 18-90 and reset the index\n",
    "df_admission=df_admission[(df_admission.AGE_UPON_ADMIT>=18)&(df_admission.AGE_UPON_ADMIT<=90)]\n",
    "df_admission = df_admission.reset_index(drop = True)\n",
    "df_admission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6a2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by subject_ID and admission date\n",
    "df_admission = df_admission.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
    "df_admission = df_admission.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f787143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create READMISSION_TIME and READMISSION_TYPE. For admissions with \"ELECTIVE\" as the next readmission, use backfill to replace the na data\n",
    "df_admission['READMISSION_TIME']=np.nan\n",
    "df_admission['READMISSION_TYPE']=np.nan\n",
    "for i in range(len(df_admission)-1):\n",
    "    if df_admission['SUBJECT_ID'][i]==df_admission['SUBJECT_ID'][i+1] and df_admission['ADMISSION_TYPE'][i+1]!='ELECTIVE':\n",
    "        df_admission['READMISSION_TIME'][i]=df_admission['ADMITTIME'][i+1]\n",
    "        df_admission['READMISSION_TYPE'][i]=df_admission['ADMISSION_TYPE'][i+1]\n",
    "df_admission[['READMISSION_TIME','READMISSION_TYPE']] = df_admission.groupby(['SUBJECT_ID'])[['READMISSION_TIME','READMISSION_TYPE']].fillna(method = 'bfill')\n",
    "df_admission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate date interval between discharge date and the next admission date\n",
    "df_admission['READMISSION_INTERVAL']=(df_admission.READMISSION_TIME-df_admission.DISCHTIME).dt.days\n",
    "df_admission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dbf82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the date interval and see if there's any outlier/error cases. Some date intervals are less than zero and need to be removed.\n",
    "plt.hist(df_admission.READMISSION_INTERVAL, bins='auto') \n",
    "plt.title(\"Readmission interval\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce2dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define readmission as a re-occurance of admission within 30 days after the last discharge\n",
    "df_admission['READMISSION_STATUS'] = np.where((df_admission['READMISSION_INTERVAL']<=30) & (df_admission['READMISSION_INTERVAL']>=0) ,'Readmitted','Non-readmitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome label distribution\n",
    "df_admission.READMISSION_STATUS.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4458c3",
   "metadata": {},
   "source": [
    "# Part 2: Preprocess df_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes.CATEGORY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the discharge summaries\n",
    "df_dis_sum=df_notes[df_notes.CATEGORY=='Discharge summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10657514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dis_sum=df_dis_sum.sort_values(['HADM_ID','CHARTDATE']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if only one discharge summary can be matched with each admission id. \n",
    "# Turns out that 12646 of the notes records have duplicate admission ids, which means there could be multiple discharge summaries for one single admission.\n",
    "duplicates=df_dis_sum[df_dis_sum.duplicated(['HADM_ID'],keep=False)]\n",
    "len(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine discharge summaries for each admission id\n",
    "df_dis_sum['TEXT_AGG'] = df_dis_sum.groupby(['HADM_ID'])['TEXT'].transform(lambda x: '|'.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on HADM_ID and keep only 'HADM_ID','TEXT_AGG' columns\n",
    "df_dis_sum_agg = df_dis_sum[['HADM_ID','TEXT_AGG']].drop_duplicates(subset=['HADM_ID']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a35cfe",
   "metadata": {},
   "source": [
    "# Part 3: Combine df_admission and df_dis_sum_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2115ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two tables\n",
    "df_adm_dis_sum=df_admission.merge(df_dis_sum_agg, on='HADM_ID', how='left').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbdb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any admission record can't be matched with a discharge summary\n",
    "df_adm_dis_sum[df_adm_dis_sum['TEXT_AGG'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf5f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the rows in which the discharge summary is not null\n",
    "df_adm_dis_sum=df_adm_dis_sum[df_adm_dis_sum['TEXT_AGG'].notnull()].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be33b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of positive and negative labels in the outcome variable\n",
    "df_adm_dis_sum.READMISSION_STATUS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined file into df_adm_dis_sum_not_cleaned.csv\n",
    "df_adm_dis_sum.to_csv(r'C:\\USFCA\\HS 651\\df_adm_dis_sum_not_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ce7e32",
   "metadata": {},
   "source": [
    "# Part 4: Data cleaning for notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I didn't use word frequency to determine stopwords but here's the code to identify the most common words:\n",
    "# from collections import Counter\n",
    "# sort_orders = sorted(Counter(word).items(), key=lambda x: x[1], reverse=True)\n",
    "# for i in sort_orders:\n",
    "    # print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7acdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up punctuation and number list\n",
    "import string\n",
    "punc_numb=string.punctuation+'0123456789'\n",
    "\n",
    "# Load in spacy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stops=nlp.Defaults.stop_words\n",
    "\n",
    "# Define text cleaning function\n",
    "def clean_text(text):\n",
    "    text=text.replace('\\n',' ')\n",
    "    text=text.replace('\\r',' ')\n",
    "    \n",
    "    # Replace all the punctuations and numbers to space\n",
    "    t = text.maketrans(dict.fromkeys(punc_numb,' '))\n",
    "    text = text.lower().translate(t)\n",
    "    \n",
    "    # Lemmatize the words in text and save the words in list 'text_lemma'\n",
    "    text=nlp(text)\n",
    "    text_lemma=[]\n",
    "    for token in text:\n",
    "        text_lemma.append(token.lemma_)\n",
    "    \n",
    "    # Remove stop words and words with length<3 and extra spaces\n",
    "    text_lemma_nonstop = [w for w in text_lemma if not w in stops and len(w) >= 3 and not str(w).isspace()]\n",
    "    \n",
    "    # Concatenate items in the list to string\n",
    "    text_clean = \" \".join(text_lemma_nonstop)\n",
    "    \n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90076e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add progress bar to the cell below to check remaining executing time. \n",
    "# The tqdm function only works for the for loops so I didnt use the lambda function here. The process took me 5 hours.\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b2e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(df_adm_dis_sum))):\n",
    "    df_adm_dis_sum['TEXT_AGG'][i]=clean_text(df_adm_dis_sum['TEXT_AGG'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another approach is to use the lambda fucntion: df_adm_dis_sum['TEXT_AGG']=df_adm_dis_sum['TEXT_AGG'].map(lambda x: clean_text(x))\n",
    "# However, the progress of execution won't be shown and it's hard to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac038c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataframe to a csv file for modeling use\n",
    "df_adm_dis_sum.to_csv(r'C:\\USFCA\\HS 651\\df_adm_dis_sum.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
