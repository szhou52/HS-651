{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "30-day readmission Bert_500 prediction.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMxoCCElPpYnWBFUBMB1F05",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szhou52/HS-651/blob/main/30_day_readmission_Bert_500_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYl_pwlNXoex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da1c6f32-437c-409b-f6c5-36afab6f4984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.1.3\n",
            "  Downloading pyspark-3.1.3.tar.gz (214.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 214.0 MB 7.4 kB/s \n",
            "\u001b[?25hCollecting spark-nlp==3.4.2\n",
            "  Downloading spark_nlp-3.4.2-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 82.5 MB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 95.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.3-py2.py3-none-any.whl size=214463484 sha256=e6518d6211d605c2d30cd7f7adcc3647d09377a6913177258a9a263e460ac70b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/8e/49/44c110bb8e008d0778c6577d600d46047c6478ecca3f8f1517\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, spark-nlp, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.3 spark-nlp-3.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.1.3 spark-nlp==3.4.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start(gpu=True)\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "id": "ErH4tyZTXyue",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "67b458aa-cb55-4499-97ef-1f9c55ac34f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.4.2\n",
            "Apache Spark version:  3.1.3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f8061163390>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://60b1acb9731e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *"
      ],
      "metadata": {
        "id": "UXqlYkyjX68X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import SQLTransformer\n",
        "from pyspark.ml.feature import StringIndexer"
      ],
      "metadata": {
        "id": "ZLqGMhxLX8_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "D7pJ2Q1ZX-y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "t6yrSKNtYFyB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c322ab5-083d-4bcd-fa9b-4f9a1452b5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "readmission=pd.read_csv('gdrive/MyDrive/Colab_notebook/df_adm_dis_sum.csv')"
      ],
      "metadata": {
        "id": "Si6ia36dYIA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slice eath document into parts with 500 (or less) tokens each"
      ],
      "metadata": {
        "id": "ELGYl0ysf_UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test=train_test_split(readmission,test_size=0.2, random_state=42)\n",
        "\n",
        "# sub-sampling the negatives (non-readmitted) on the training set\n",
        "df_train_readm=df_train[df_train.READMISSION_STATUS=='Readmitted']\n",
        "df_train_non_readm=df_train[df_train.READMISSION_STATUS=='Non-readmitted']\n",
        "df_train_sub = pd.concat([df_train_readm, df_train_non_readm.sample(n = len(df_train_readm), random_state = 42)],axis = 0)"
      ],
      "metadata": {
        "id": "DwEMlbwQqDsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_sub=df_train_sub.reset_index(drop=True)\n",
        "df_test=df_test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "KYworW25rOo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def five_hund_split(text):\n",
        "  sublist_list=[]\n",
        "  token_list=text.split(\" \")\n",
        "  if len(token_list)<=500:\n",
        "    sublist_list.append(text)\n",
        "  else:\n",
        "      num_sublist=int(math.modf(len(token_list)/500)[1]+1)\n",
        "      sublist_list=[0]*num_sublist\n",
        "      for i in range(num_sublist):\n",
        "          sublist_list[i]=token_list[500*i:500*(i+1)]\n",
        "          sublist_list[i]=\" \".join(sublist_list[i])\n",
        "  return(sublist_list)"
      ],
      "metadata": {
        "id": "JhTXlB-afRM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_AGG_five_hund=[]\n",
        "HADM_ID=[]\n",
        "READMISSION=[]\n",
        "\n",
        "from tqdm import tqdm\n",
        "for i in tqdm(range(len(df_train_sub))):\n",
        "  sublist_list=five_hund_split(df_train_sub['TEXT_AGG'][i])\n",
        "  admission_id=df_train_sub['HADM_ID'][i]\n",
        "  readmission_status=df_train_sub['READMISSION_STATUS'][i]\n",
        "  for sublist in sublist_list:\n",
        "    TEXT_AGG_five_hund.append(sublist)\n",
        "    HADM_ID.append(admission_id)\n",
        "    READMISSION.append(readmission_status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVRKZii2koAn",
        "outputId": "6d41acda-8e68-4406-c1d2-1bc65c39a4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4522/4522 [00:00<00:00, 12402.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_sliced= pd.DataFrame(list(zip(HADM_ID,TEXT_AGG_five_hund,READMISSION)),\n",
        "               columns =['HADM_ID','TEXT_AGG','readmission_status'])"
      ],
      "metadata": {
        "id": "haEb6J_OocYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_AGG_five_hund=[]\n",
        "HADM_ID=[]\n",
        "READMISSION=[]\n",
        "\n",
        "from tqdm import tqdm\n",
        "for i in tqdm(range(len(df_test))):\n",
        "  sublist_list=five_hund_split(df_test['TEXT_AGG'][i])\n",
        "  admission_id=df_test['HADM_ID'][i]\n",
        "  readmission_status=df_test['READMISSION_STATUS'][i]\n",
        "  for sublist in sublist_list:\n",
        "    TEXT_AGG_five_hund.append(sublist)\n",
        "    HADM_ID.append(admission_id)\n",
        "    READMISSION.append(readmission_status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7ukn8Y_p-il",
        "outputId": "cb9c3c25-08ad-4f81-b98b-b07d9550d9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9262/9262 [00:00<00:00, 12965.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_sliced= pd.DataFrame(list(zip(HADM_ID,TEXT_AGG_five_hund,READMISSION)),\n",
        "               columns =['HADM_ID','TEXT_AGG','readmission_status'])"
      ],
      "metadata": {
        "id": "OmqMIHY3qsfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the pandas df to a spark df\n",
        "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
        "train = spark.createDataFrame(df_train_sliced)\n",
        "test= spark.createDataFrame(df_test_sliced)"
      ],
      "metadata": {
        "id": "qa9kAYwbCd8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipelines"
      ],
      "metadata": {
        "id": "k81AO0qlrvEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Produce pipeline for data cleaning and sentence(discharge summary) embedding\n",
        "document_assembler = DocumentAssembler() \\\n",
        "      .setInputCol(\"TEXT_AGG\") \\\n",
        "      .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "      .setInputCols([\"document\"]) \\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "lemmatizer = Lemmatizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"lemma\") \\\n",
        "    .setDictionary(\"gdrive/MyDrive/Colab_notebook/AntBNC_lemmas_ver_001.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")\n",
        "\n",
        "bert_embeddings = BertEmbeddings.pretrained()\\\n",
        "  .setInputCols([\"document\",\"lemma\"])\\\n",
        "  .setOutputCol(\"bert_embeddings\")\\\n",
        "  .setCaseSensitive(False)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"bert_embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "embeddings_finisher = EmbeddingsFinisher() \\\n",
        "      .setInputCols([\"sentence_embeddings\"]) \\\n",
        "      .setOutputCols([\"finished_sentence_embeddings\"]) \\\n",
        "      .setOutputAsVector(True)\\\n",
        "      .setCleanAnnotations(False)\n",
        "\n",
        "explodeVectors = SQLTransformer(statement=\n",
        "      \"SELECT EXPLODE(finished_sentence_embeddings) AS features, * FROM __THIS__\")\n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = \"readmission_status\", outputCol = \"label\")\n",
        "\n",
        "nlp_pipeline_Bert = Pipeline(\n",
        "stages=[document_assembler, \n",
        "          tokenizer,\n",
        "          lemmatizer,\n",
        "          bert_embeddings,\n",
        "          embeddingsSentence,\n",
        "          embeddings_finisher,\n",
        "          explodeVectors,\n",
        "          label_stringIdx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvkN3GUGrr7m",
        "outputId": "d6dad004-6227-4585-9de5-1fe0117ca63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small_bert_L2_768 download started this may take some time.\n",
            "Approximate size to download 139.6 MB\n",
            "[OK!]\n",
            "CPU times: user 36.6 ms, sys: 7.7 ms, total: 44.3 ms\n",
            "Wall time: 3.61 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_bert_five_hund=nlp_pipeline_Bert.fit(train)"
      ],
      "metadata": {
        "id": "vCqYy2LdBp19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_bert_five_hund.write().overwrite().save('gdrive/MyDrive/Colab_notebook/Models_Pipelines/bert_500_readmission')"
      ],
      "metadata": {
        "id": "oNmTSw21EVyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.pipeline import PipelineModel\n",
        "nlp_bert_five_hund= PipelineModel.load(\"gdrive/MyDrive/Colab_notebook/Models_Pipelines/bert_500_readmission/\")"
      ],
      "metadata": {
        "id": "bNKNsfwtEjDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform the training and test set\n",
        "processed_train=nlp_bert_five_hund.transform(train)\n",
        "processed_test=nlp_bert_five_hund.transform(test)"
      ],
      "metadata": {
        "id": "9kyCYEVOEs_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine rows based on admission id\n",
        "from pyspark.sql.functions import collect_list\n",
        "from pyspark.sql import functions as F\n",
        "processed_train_combined = processed_train.groupby('HADM_ID').agg(collect_list('features').alias(\"features\"),F.min(processed_train.label))\n",
        "processed_test_combined= processed_test.groupby('HADM_ID').agg(collect_list('features').alias(\"features\"),F.min(processed_test.label))"
      ],
      "metadata": {
        "id": "0-oAqV5uFPfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_test_combined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPh-rWsoF9Z3",
        "outputId": "35beff49-e509-4a27-9fd2-e43f25e56e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+----------+\n",
            "|HADM_ID|            features|min(label)|\n",
            "+-------+--------------------+----------+\n",
            "| 120327|[[0.0921542346477...|       1.0|\n",
            "| 122377|[[0.0384613610804...|       1.0|\n",
            "| 124703|[[0.1649432927370...|       1.0|\n",
            "| 126716|[[0.0280453320592...|       1.0|\n",
            "| 127229|[[0.1691382229328...|       1.0|\n",
            "| 127525|[[0.1240143254399...|       1.0|\n",
            "| 127964|[[0.0712104514241...|       0.0|\n",
            "| 137634|[[0.0280135795474...|       1.0|\n",
            "| 168079|[[0.0622289851307...|       1.0|\n",
            "| 168808|[[0.0853902623057...|       1.0|\n",
            "| 101738|[[0.2376184910535...|       0.0|\n",
            "| 101756|[[0.1153774484992...|       1.0|\n",
            "| 104084|[[0.1021297946572...|       1.0|\n",
            "| 108589|[[0.1012754812836...|       1.0|\n",
            "| 115838|[[-0.069325789809...|       1.0|\n",
            "| 117383|[[0.1129594817757...|       1.0|\n",
            "| 131111|[[0.0992296636104...|       1.0|\n",
            "| 150665|[[0.0606598705053...|       1.0|\n",
            "| 182711|[[0.0030397975351...|       1.0|\n",
            "| 188057|[[-0.027117162942...|       1.0|\n",
            "+-------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the transformed training and test set as orc\n",
        "processed_train_combined.write.orc(\"gdrive/MyDrive/Colab_notebook/transformed_data/bert_500_train\")\n",
        "processed_test_combined.write.orc(\"gdrive/MyDrive/Colab_notebook/transformed_data/bert_500_test\")"
      ],
      "metadata": {
        "id": "cdkLitflHbB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train=processed_train_combined.toPandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnH5ooejL4SB",
        "outputId": "eb2ddf8e-8f6a-461e-fbf1-465f16771330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/pandas/conversion.py:87: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
            "  Unsupported type in conversion to Arrow: VectorUDT\n",
            "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd_test=processed_test_combined.toPandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu-xDB74L_-x",
        "outputId": "6dad38de-5be7-4149-e5fe-196efafb2119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/pandas/conversion.py:87: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
            "  Unsupported type in conversion to Arrow: VectorUDT\n",
            "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "pd_test['features'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_QwL065OmCP",
        "outputId": "094deb5b-81c0-4cf8-dabc-683594ab4e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DenseVector([0.0922, -0.0392, 0.0624, -0.1581, 0.1529, -0.1255, 0.1055, -0.0642, 0.0801, -0.2005, 0.1021, -0.1915, -0.0902, -0.3402, 0.1127, -0.3634, -0.3042, 0.3004, 0.1564, 0.2389, 0.2338, -0.1066, -0.2129, 0.0182, -0.0363, 0.1554, -0.5223, 0.1434, 0.0287, 0.1994, -0.1604, -0.0372, -0.1737, 0.1268, -0.7049, 0.2984, -0.3897, -0.0976, 0.2272, 0.0617, -0.2109, 0.0722, -0.0901, -0.2205, -0.0, -0.4101, -0.1756, 0.1586, 0.3681, -0.4862, -0.1079, 0.186, -0.0009, 0.1073, 0.1276, 0.0969, 0.2232, 0.1403, -0.2201, 0.037, 0.0517, 0.1135, -0.7833, 0.0378, -0.0355, -0.1085, -0.5104, -0.3516, 0.1113, 0.3572, 0.1642, -0.297, -0.2195, -0.2544, 0.664, -0.264, -0.2465, -0.1743, -0.2322, -0.3486, -0.0208, -0.0262, -0.4049, 0.2748, -0.1267, 0.3098, 0.4756, 0.1902, 0.0268, -0.2775, -0.0969, -0.0863, 0.2576, -0.544, 0.0946, 0.2653, 0.0269, 0.1624, 0.3014, -0.3021, -0.0438, -0.3842, -0.1972, -0.3052, -0.2254, -0.4373, 0.5011, -0.0269, 0.0452, -0.1322, 0.2166, -0.2457, 0.0457, 0.2552, 0.3509, 0.0249, 0.1615, -0.0359, 0.1053, 0.0477, -0.127, 0.2923, 0.3198, -0.2175, -0.3377, -0.2196, 0.3415, 0.4638, 0.0833, -0.3657, -0.1336, -0.008, -0.1058, 0.4312, -0.2842, -0.6051, 0.0963, -0.2053, -0.1403, -0.0531, -0.0692, 0.3425, -0.1621, -0.31, -0.2389, -0.2807, 0.2546, -0.0435, -0.1694, -0.6159, 0.0968, 0.2688, -0.062, -0.0642, 0.0425, 0.2981, -0.0299, 0.3796, -0.1967, -0.2202, -0.4811, -0.4935, -0.2747, -0.0037, 0.2388, 0.0709, 0.3538, 0.4202, -0.0884, -0.2506, 0.0851, -0.1854, -0.0051, 0.0914, 0.0978, 0.3431, 0.0887, 0.1887, -0.2958, -0.1726, -0.2793, 0.1455, 0.0123, 0.3461, 0.0898, 0.1852, -0.2002, -0.0042, 0.0862, -0.114, 0.0921, 0.2625, 0.1578, 0.2059, -0.2441, 0.0674, -0.2757, 0.1223, 0.1642, 0.0801, -0.0921, -1.3333, 0.2468, -0.035, -0.0553, 0.3791, 0.3034, 0.1605, -0.5337, 0.0395, -0.016, 0.0243, -0.3825, -0.2561, -0.2963, 0.0195, 0.4088, 0.1601, -0.1858, -0.4414, -0.0389, 0.0567, 0.2174, 0.1452, -0.0943, 0.3049, 0.3496, -0.0002, 0.5277, -0.1034, 0.5348, 0.0831, -0.4743, -0.0327, -0.362, 0.2544, -0.002, 0.1493, -0.3265, 0.4086, 0.2547, -0.0292, 0.0802, 0.4117, 0.3815, 0.0752, 0.5605, 0.0637, -0.193, 0.1242, -0.0019, -0.3302, -0.2917, 0.2573, -0.2764, 0.0057, 0.0089, 0.2409, 0.0455, -0.0466, 0.47, 0.7496, -0.1119, 0.0675, 0.1161, 0.2478, -0.5736, -0.4269, 0.2176, -0.1377, 0.0745, -0.1377, -0.4665, 0.267, -0.4533, 0.1842, -0.3918, -0.1197, 0.1627, -0.1158, -0.0018, -0.1763, -0.5894, -0.3052, -0.052, 0.0445, -0.0748, -0.1889, -0.3202, -0.028, 0.5957, -0.3665, 0.325, 0.1458, -0.4403, -0.0134, 0.1778, -0.1361, -0.1263, 0.0011, 0.0203, -0.0732, 0.2899, 0.0676, 0.3507, 0.1767, 0.018, 0.1262, -0.4219, 0.0072, -0.1076, 0.275, -0.109, 0.3687, 0.2077, -0.2704, -0.1071, 0.0645, 0.1428, -0.1313, -0.0066, 0.124, 0.0912, 0.0191, 0.1041, 0.1673, -0.0985, 0.0618, -0.141, 0.2549, -0.3181, -0.2344, 0.1679, -0.0052, 0.1011, -0.317, -0.665, 0.1946, 0.1738, -0.2007, 0.0517, -0.5149, -0.3053, 0.7073, -0.0507, 0.4014, -0.1705, -0.0171, 0.2453, 0.171, -0.0108, 0.2046, -0.2803, -0.1877, 0.1074, 0.0365, 0.0154, 0.2798, -0.4238, -0.4695, -0.1562, -0.1259, -0.1399, 0.4796, 0.231, -0.1414, 0.2174, -0.041, -0.2533, 0.1852, -0.1627, 0.5147, -0.3563, -0.2542, -0.0513, 0.3724, -0.3938, -0.4871, -0.4148, 0.42, 0.2587, 0.2987, -0.1904, -0.2981, -0.2477, -0.0068, 0.3934, -0.3548, 0.0769, -0.1103, 0.0177, 0.1046, -0.4493, 0.4, -0.2417, -0.4661, 0.2725, 0.4008, 0.1921, 0.5449, -0.2078, -0.6538, 0.2375, -0.3906, -0.0019, 0.2425, -0.3089, -0.2773, 0.1549, -0.0171, -0.1682, 0.1555, 0.4538, 0.2669, 0.0048, -0.1087, 0.1035, -0.0379, -0.0641, 0.0175, 0.2281, -0.3508, 0.0645, 0.002, 0.1004, 0.0752, -0.384, 0.2392, -0.0183, 0.3221, -0.0496, -0.2834, 0.1346, 0.2972, 0.1678, -0.129, -0.2292, -0.6519, 0.0856, -0.1014, 0.0551, -0.2398, -0.037, 0.5415, 0.4108, 0.1072, 0.3419, -0.2344, 0.044, 0.2369, 0.2969, -0.0606, 0.2458, -0.0806, 0.2498, -0.265, 0.3462, -0.2614, -0.1335, 0.2337, 0.599, 0.2003, 0.7733, -0.0517, 0.1314, 0.0481, -0.227, 0.308, -0.4822, -0.1698, -0.1271, 0.5799, 0.0921, 0.0962, -0.0932, 0.341, -0.3199, 0.0289, 0.3109, -0.0541, 0.1237, 0.193, 0.007, -0.2077, 0.0456, -0.4635, 0.1774, -0.2852, 0.1534, 0.3155, -0.2807, 0.137, 0.3297, 0.0328, 0.2863, 0.1225, -0.1775, 0.1491, 0.0462, 0.2922, 0.0707, -0.2973, 0.1142, -0.0184, -0.0305, -0.5793, -0.0135, 0.087, -0.4122, 0.1841, 0.0998, -0.0642, -0.1648, 0.0331, -0.0797, 0.2897, -0.2826, -0.0132, 0.4498, 0.6779, 0.0246, -0.0951, 0.5463, 0.3275, -0.1098, 0.0144, 0.1316, -0.1875, 0.1546, -0.0009, -0.1594, -0.0275, -0.0852, -0.3238, 0.1162, -0.1541, -0.1725, 0.4132, 0.0739, -0.5638, 0.0666, 0.0581, 0.2489, 0.0756, -0.1734, 0.2724, 0.3764, 0.2329, 0.3196, -0.1318, 0.0009, 0.0966, -0.4631, 0.4563, 0.2291, 0.2145, 0.05, 0.3514, 0.1494, -0.0534, 0.3775, -0.0761, -0.4242, -0.26, -0.0494, -0.1458, -0.3884, 0.0068, 0.1323, 0.0434, 0.2285, 0.0732, 0.3185, -0.1657, -0.0597, -0.5356, 0.2657, 0.04, 0.0548, 1.0813, -0.2031, -0.1432, -0.0563, -0.2643, 0.6745, -0.06, 0.2212, 0.1546, -0.007, 0.1687, 0.106, -0.4514, 0.2222, -0.1312, -0.2068, 0.0969, -0.3209, 0.2401, -0.2195, -0.5069, 0.0391, -0.1464, 0.0665, 0.0551, -0.2826, -0.1361, -0.5414, 0.2085, -0.6138, 0.0888, -0.1016, 0.305, 0.0241, 0.6434, -0.1593, -0.3789, 0.2581, -0.0366, 0.2106, -0.497, 0.2036, -0.2631, -0.055, 0.0554, -0.0484, -0.2669, 0.2899, -0.2283, -0.1604, -0.023, -0.1186, 0.1532, -0.3477, -0.0674, 0.5021, 0.2096, -0.2077, -0.0273, -0.1185, -0.1677, 0.2489, -0.6346, 0.1272, -0.1709, 0.9976, -0.2801, -0.4172, 0.0522, 0.1668, 0.2885, 0.0561, -0.0921, -0.1468, 0.0378, 0.4651, 0.2191, -0.0946, -0.2665, -0.0343, 0.1621, 0.1302, -0.2441, 0.0052, 0.0018, -0.3171, 0.3657, -0.0838, 0.021, 0.0242, 0.0464, -0.1201, -0.307, -0.2681, 0.1568, -0.2973, -0.0364, -0.1498, -0.3999, 0.0592, -0.1077, 0.0969, -0.1236, -0.0784, 0.1486, 0.1941, 0.2485, -0.0065, 0.4843, 0.1173, -0.1285, -0.1152, 0.1867, 0.7378, 0.0196, -0.2823, -0.0773, 0.4458, -0.4699, -0.0877, 0.0886, -0.0923, 0.1551, -0.0444, -0.0591, -0.1546, -0.3709, -0.2654, 0.2702, 0.0861, 0.1515, 0.0061, -0.0682, -2.2913, 0.11, 0.3863, 0.015, 0.0209, 0.0017, 0.1278, 0.1219, 0.0296, -0.3347, 0.3226, -0.1551, 0.2283, 0.0082, -0.2144, -0.3861, 0.1324, -0.0161, 0.0031, -0.1838, 0.0018, 0.4551, -0.117, -0.669, 0.7054, 0.328, -0.2846, -0.3286, 0.0579, -0.1005, 0.2173, -0.0551, 0.3802, -0.2703, -0.0529, -0.2558, 0.0641, -0.2449, -0.1395, -0.1205, 0.256, 0.1499, -0.1301, -0.1315, -0.0415, 0.318, 0.1349, -0.0974, -0.0574, -0.3105, -0.0469, 0.1061, 0.1393, -0.0759, -0.1968, -0.1125])]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd_test['features'][10][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_EI3a5IP-9Q",
        "outputId": "369554dd-92a1-4036-e750-dc09a7d78209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23761849105358124"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to compute average embedding vector\n",
        "def average_emb(df):\n",
        "  for i in range(len(df)):\n",
        "    new_embedding_list=[]\n",
        "    embedding_list=df['features'][i]\n",
        "    for k in range(len(embedding_list)):\n",
        "      sentence_embedding=embedding_list[k]\n",
        "      new_embedding_list.append(sentence_embedding)\n",
        "    df['features'][i]=[sum(sub_list) / len(sub_list) for sub_list in zip(*new_embedding_list)]\n",
        "  return(df)"
      ],
      "metadata": {
        "id": "-MBk4N6MM7j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train=average_emb(pd_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVex39zkRtM8",
        "outputId": "600a13e3-77df-48a2-e353-060ce4074982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train.to_csv('gdrive/MyDrive/Colab_notebook/transformed_data/bert_500_train.csv')"
      ],
      "metadata": {
        "id": "beQQHfITSFXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_test=average_emb(pd_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAgROmItSa-j",
        "outputId": "1e6a770a-9b2c-44e0-82df-b646a99de5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd_test.to_csv('gdrive/MyDrive/Colab_notebook/transformed_data/bert_500_test.csv')"
      ],
      "metadata": {
        "id": "HPu0eF_ASet7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train=pd.read_csv('gdrive/MyDrive/Colab_notebook/transformed_data/bert_500_train.csv')\n",
        "pd_test=pd.read_csv('gdrive/MyDrive/Colab_notebook/transformed_data/bert_500_test.csv')"
      ],
      "metadata": {
        "id": "OggQy4SkSxE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_train.label=pd_train['min(label)'].astype(\"int\")\n",
        "pd_test.label=pd_test['min(label)'].astype(\"int\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3knwLuTSxbK",
        "outputId": "98e0ec88-bbc5-416e-a72c-489bcdb9774f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=pd_train.features\n",
        "y_train=pd_train['min(label)']\n",
        "\n",
        "X_test=pd_test.features\n",
        "y_test=pd_test['min(label)']"
      ],
      "metadata": {
        "id": "dCjNMdanURn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_invalid_index=[]\n",
        "for i in range(len(X_train)):\n",
        "  if X_train[i]=='[]':\n",
        "    train_invalid_index.append(i)\n",
        "X_train=X_train.drop(train_invalid_index)"
      ],
      "metadata": {
        "id": "b2lXGe4ogzeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train.drop(train_invalid_index)"
      ],
      "metadata": {
        "id": "0Hd4Nm0KnXWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_invalid_index=[]\n",
        "for i in range(len(X_test)):\n",
        "  if X_test[i]=='[]':\n",
        "    test_invalid_index.append(i)\n",
        "X_test=X_test.drop(test_invalid_index)"
      ],
      "metadata": {
        "id": "Oc_vPix_luGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test=y_test.drop(test_invalid_index)"
      ],
      "metadata": {
        "id": "RKjOm0mFneGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_trans=[]\n",
        "for doc in X_train:\n",
        "    embedding=doc[1:-1]\n",
        "    embedding_list=embedding.split(\",\")\n",
        "    str_to_num_list=[]\n",
        "    for num_str in embedding_list:\n",
        "        str_to_num_list.append(float(num_str))\n",
        "    X_train_trans.append(str_to_num_list)"
      ],
      "metadata": {
        "id": "LUf-midNkzbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_trans=[]\n",
        "for doc in X_test:\n",
        "    embedding=doc[1:-1]\n",
        "    embedding_list=embedding.split(\",\")\n",
        "    str_to_num_list=[]\n",
        "    for num_str in embedding_list:\n",
        "        str_to_num_list.append(float(num_str))\n",
        "    X_test_trans.append(str_to_num_list)"
      ],
      "metadata": {
        "id": "aFRNnBVvUvht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeling"
      ],
      "metadata": {
        "id": "kpWUiBN4mHRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQDKg47enGbV",
        "outputId": "3680b74c-bbf8-4ea8-baf7-5885ad1668b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "SYWGmHN7lacL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert vs Logistic regression\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "param= dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
        "scoring='roc_auc'\n",
        "\n",
        "logistic_clf_bert = BayesSearchCV(estimator=LogisticRegression(), search_spaces=param, scoring=scoring, n_jobs=-1, cv=cv)"
      ],
      "metadata": {
        "id": "F3Cxq7zVnMH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_clf_bert.fit(X_train_trans,y_train)"
      ],
      "metadata": {
        "id": "bW6fryuDnNxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_clf_bert_best=logistic_clf_bert.best_score_"
      ],
      "metadata": {
        "id": "omc7BbeD2mkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_clf_bert_best"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p_NvkVM2ntU",
        "outputId": "04b16320-6a1d-41f8-ce47-6542f4bff926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6474705748220536"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob_logistic_clf_bert = logistic_clf_bert.predict_proba(X_test_trans)\n",
        "roc_auc_y_prob_logistic_clf_bert=roc_auc_score(y_test, y_prob_logistic_clf_bert[:,1])"
      ],
      "metadata": {
        "id": "uLw4Z7FI2ssj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_y_prob_logistic_clf_bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFJV9fqZ2zp9",
        "outputId": "14a72114-b48e-4590-ad0b-a2c41df00bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6467185243656803"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bert and Linear SVM \n",
        "c_values=[100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "param= dict(C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
        "scoring='roc_auc'\n",
        "\n",
        "lsvc_clf_bert = BayesSearchCV(estimator=LinearSVC(), search_spaces=param, scoring=scoring, n_jobs=-1, cv=cv)"
      ],
      "metadata": {
        "id": "aPu74U2m227L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsvc_clf_bert.fit(X_train_trans,y_train)"
      ],
      "metadata": {
        "id": "nQFFHfIeTn6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsvc_clf_bert_best=lsvc_clf_bert.best_score_"
      ],
      "metadata": {
        "id": "3pABAr1gryIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsvc_clf_bert_best"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FegZBIszr8Ar",
        "outputId": "94005710-2603-4285-fd3a-36cbcfffdfb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6466278427957945"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    }
  ]
}